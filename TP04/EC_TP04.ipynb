{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engenharia do Conhecimento 2022/2023\n",
    "\n",
    "## TP04: Linear models for Regression and Classification\n",
    "\n",
    "*A Machine Learning Tutorial by Andre Falcao (DI/FCUL 2021-2022)*\n",
    "\n",
    "*Revised by Catia Pesquita (2022-2023) and by Lu√≠s Correia (2023-2024)*\n",
    "\n",
    "### Summary\n",
    "\n",
    "1. The essence of Linear Regression\n",
    "2. Linear Regression in Scikit-Learn\n",
    "3. Regularized Models: Ridge Regression and Lasso\n",
    "4. Logistic Regression for Classification \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The essence of Linear Regression\n",
    "\n",
    "### 1.1. Computing Linear regression manually\n",
    "\n",
    "\n",
    "We know that the parameters of a linear model can be computed according to the equation\n",
    "\n",
    "$\\beta = (X^T.X)^{-1}.X^T.Y$ &emsp; &emsp; &emsp; (1)\n",
    "\n",
    "Let's check it out for the [diabetes dataset form the toy examples of scikit learn](https://scikit-learn.org/stable/datasets/toy_dataset.html) that has 10 independent variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    "X_diabetes, y_diabetes=load_diabetes(return_X_y=True)\n",
    "\n",
    "#show data set, with target values in first column\n",
    "pd.DataFrame(X_diabetes, y_diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this procedure we first need to add one `[1]` column to the whole dataset that will emcompass the bias of the model (intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.insert(X_diabetes, 0, 1, axis=1)\n",
    "X1.shape\n",
    "pd.DataFrame(X1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will divide the full dataset into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y_diabetes, test_size=0.2, random_state=22)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the following procedure just computes the Beta parameters by sequentially solving equation (1) above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtt=np.transpose(X_train) #Xtt - the transposed X matrix (XT)\n",
    "print(Xtt.shape) #<-check the matrix dimensions\n",
    "gram=np.dot(Xtt, X_train) #the dot product between XT and X (XT.X)\n",
    "print(gram.shape) #<-check the matrix dimensions\n",
    "gram_inv=np.linalg.inv(gram) #now we invert: (XT.X)^-1\n",
    "print(gram_inv.shape) #<-check the matrix dimensions\n",
    "X_part = np.dot(gram_inv,Xtt) #the dot product (XT.X)^-1 .XT\n",
    "print(X_part.shape) #<-check the matrix dimensions \n",
    "Beta_est=np.dot(X_part, y_train) #and the final dot product with the output vector XT (XT.X)^-1 .XT .Y\n",
    "\n",
    "print(Beta_est) #the values of all betas for 0...N\n",
    "\n",
    "#print(\"The bias is: %9.3f\" % Beta_est[0]) #this is the intercept, beta_zero, or alpha \n",
    "print(\"The parameters are (notice that the first, B0, is the intercept): \") #the coefficients \n",
    "for i, beta in enumerate(Beta_est[0:]):\n",
    "    print(\"\\t B%2d -> %9.3f\"% (i, beta))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Predictions with the linear regression model\n",
    "\n",
    "Making predictions is trivial. It is just a matrix multiplication of the parameters with the dataset for which we want to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#computes predicted values by taking the x values and muliplying be the corresponding beta coefficients\n",
    "my_preds=np.dot(X_test,Beta_est) \n",
    "\n",
    "#histogram of predicted values\n",
    "plt.hist(my_preds, bins=20, alpha=.8)\n",
    "plt.xlabel(\"predicted values\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute some usual regression statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, root_mean_squared_error, max_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def printRegStatistics(truth, preds):\n",
    "    print(\"The R2 is: \", r2_score(truth, preds))\n",
    "    print(\"The rmse is: \", root_mean_squared_error(truth, preds))\n",
    "#    print(\"The rmse is: \", mean_squared_error(truth, preds, squared=False)) # this call is deprecated\n",
    "    corr, pval = pearsonr(truth, preds)\n",
    "    print(\"The Correlation Score is is: %6.4f (p-value=%e)\\n\"%(corr,pval))\n",
    "    print(\"The Maximum Error is is: \", max_error(truth, preds))\n",
    "    print(\"The Mean Absolute Error is: \", mean_absolute_error(truth, preds))\n",
    "\n",
    "printRegStatistics(y_test, my_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And compare graphically the results to the actual y values (y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.scatter(y_test, my_preds)\n",
    "plt.grid()\n",
    "#this is the 45degrees angle. The closer the predictions approach this, the better the model\n",
    "plt.plot([0, 350], [0, 350], c=\"r\")\n",
    "plt.xlabel(\"real values\")\n",
    "plt.ylabel(\"predictions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Linear regression with Python libraries\n",
    "\n",
    "### 2.1 Using scikit-learn\n",
    "\n",
    "The only difference to the above procedure that we have used for fitting our model is that here we will use the original X matrix and not X1 (which has an extra **ONE** column), so we will need to do a new train-test split this time with the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_diabetes, y_diabetes, test_size=0.2, random_state=22)\n",
    "\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "print(\"The bias is: \",  reg.intercept_)\n",
    "print(\"The other parameters are: \")\n",
    "for i, beta in enumerate(reg.coef_):\n",
    "    print(\"\\t B%2d -> %9.3f\"% (i+1, beta))\n",
    "    \n",
    "print(\"The score is: \", reg.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the results of the parameter values with the ones computed above, at the end of 1.1. They should be exactly the same! A linear regression is a stable model - always gives the same result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "A couple of questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"The score displayed above is the value of metric: \", end=\" \")\n",
    "print(\"**<your answer here>**\")\n",
    "print(\"\")\n",
    "print(\"It has been computed over the: \", end=\" \")\n",
    "print(\"**<your answer here>**\", \"set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ... finishing the comparisons\n",
    "\n",
    "Similarly let's examine the predictions graphically (should also be identical to previous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preds=reg.predict(X_test)\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.scatter(y_test, preds)\n",
    "plt.grid()\n",
    "plt.plot([0, 350], [0, 350], c=\"r\")\n",
    "plt.xlabel(\"real values\")\n",
    "plt.ylabel(\"predictions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Regularised linear models\n",
    "\n",
    "Regularised models impose boundaries on the fitted parameters, so that it is possible to have sensitivity on which variables appear most relevant for explaining the dependent `y`. The problem is that these boundaries add constraints and simple optimization of the MSE is no longer possible, requiring more complex fitting algorithms\n",
    "\n",
    "There are essentially 3 regularised linear models\n",
    "* Ridge Regression\n",
    "* Lasso (Least Absolute Shrinkage and Selection Operator)\n",
    "* Elastic nets\n",
    "\n",
    "For this class we will only discuss Ridge and Lasso, as Elastic nets are a weighted compromise betwen these two approaches. \n",
    "\n",
    "### 3.1 Ridge Regression\n",
    "\n",
    "Ridge regression applies L2 regularization, that is, it minimizes not only the MSEs (mean squared errors), but also the squared values of the parameters estimator, thus:\n",
    "\n",
    "$cost(\\beta) = MSE(\\beta) + \\frac{\\alpha}{2}\\sum^{n}_{i=1}{\\beta_i^2}$\n",
    "\n",
    "The value of $\\alpha$ defines how much to penalize the parameter values. This penalty will emphasize the importance of each variable in its contribution for explaining `y` Higher values of $\\alpha$, will cause smaller $\\beta$\n",
    "\n",
    "Selecting a value of  $\\alpha=10$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "ridge = Ridge(alpha=10, max_iter=9999999).fit(X_train, y_train)\n",
    "\n",
    "print(\"The bias is: \",  ridge.intercept_)\n",
    "print(\"The other parameters are: \")\n",
    "for i, beta in enumerate(ridge.coef_):\n",
    "    print(\"\\t B%2d -> %9.3f\"% (i+1, beta))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can of course compute the general regression statistics for the regularized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds10=ridge.predict(X_test)\n",
    "printRegStatistics(y_test, preds10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the $\\alpha$ value will have a dramatic impact on the parameters estimated as well as on the regression results. for instance for  $\\alpha=0.1$ we will have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=0.06, max_iter=9999999).fit(X_train, y_train)\n",
    "\n",
    "print(\"The bias is: \",  ridge.intercept_)\n",
    "print(\"The other parameters are: \")\n",
    "for i, beta in enumerate(ridge.coef_):\n",
    "    print(\"\\t B%02d -> %9.3f\"% (i+1, beta))\n",
    "preds0_1=ridge.predict(X_test)\n",
    "printRegStatistics(y_test, preds0_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For very low $\\alpha$ values the model is equivalent to the unconstrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=0.0001, max_iter=9999999).fit(X_train, y_train)\n",
    "\n",
    "print(\"The bias is: \",  ridge.intercept_)\n",
    "print(\"The other parameters are: \")\n",
    "for i, beta in enumerate(ridge.coef_):\n",
    "    print(\"\\t B%2d -> %9.3f\"% (i+1, beta))\n",
    "preds0_0001=ridge.predict(X_test)\n",
    "printRegStatistics(y_test, preds0_0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now is there any value of $\\alpha$ that actually is better for the current train/test partition? Let's check the R2 metric for different values and plot the results, by using grid search (test all the values of $\\alpha$ in an array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "ridge = Ridge(random_state=0, max_iter=10000)\n",
    "#lasso = Lasso(random_state=0, max_iter=10000)\n",
    "alphas=2**np.arange(-0,-10,-.05)\n",
    "tuned_parameters = [{\"alpha\": alphas}]\n",
    "n_folds = 5\n",
    "\n",
    "#cf = GridSearchCV(ridge, tuned_parameters, cv=n_folds, refit=False)\n",
    "cf = GridSearchCV(ridge, tuned_parameters, cv=n_folds, return_train_score=True, refit=False)\n",
    "cf.fit(X_train, y_train)\n",
    "tr_scores = cf.cv_results_[\"mean_train_score\"]\n",
    "tr_scores_std = cf.cv_results_[\"std_train_score\"]\n",
    "te_scores = cf.cv_results_[\"mean_test_score\"]\n",
    "te_scores_std = cf.cv_results_[\"std_test_score\"]\n",
    "\n",
    "plt.figure().set_size_inches(8, 6)\n",
    "plt.semilogx(alphas, tr_scores, label=\"train scores\")\n",
    "plt.semilogx(alphas, te_scores, label=\"test scores\")\n",
    "\n",
    "tr_std_error = tr_scores_std / np.sqrt(n_folds)\n",
    "te_std_error = te_scores_std / np.sqrt(n_folds)\n",
    "\n",
    "plt.semilogx(alphas, tr_scores + tr_std_error, \"g--\")\n",
    "plt.semilogx(alphas, tr_scores - tr_std_error, \"g--\")\n",
    "plt.semilogx(alphas, te_scores + te_std_error, \"b--\")\n",
    "plt.semilogx(alphas, te_scores - te_std_error, \"b--\")\n",
    "\n",
    "# alpha=0.2 controls the translucency of the fill color\n",
    "plt.fill_between(alphas, tr_scores + tr_std_error, tr_scores - tr_std_error, alpha=0.2)\n",
    "plt.fill_between(alphas, te_scores + te_std_error, te_scores - te_std_error, alpha=0.2)\n",
    "\n",
    "plt.ylabel(\"CV score (R2) +/- std error\")\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.axhline(np.max(tr_scores), linestyle=\"--\", color=\".3\")\n",
    "plt.axhline(np.max(te_scores), linestyle=\"--\", color=\".5\")\n",
    "best_alpha=next(iter(cf.best_params_.values()))\n",
    "plt.axvline(x = best_alpha, color = 'b', label = 'best Alpha')\n",
    "plt.legend();\n",
    "print(\"Best $alpha$ value: \", best_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a simple cross-validation\n",
    "# it shows that results are not the same as with cross validation\n",
    "\n",
    "r2_train = []\n",
    "r2_test = []\n",
    "#rmse_train = []\n",
    "#rmse_test = []\n",
    "#generate 160 values of alpha in [2^(-2)...2^(-10)]\n",
    "alphas=2**np.arange(-2,-10,-.05)\n",
    "for alpha in alphas:\n",
    "    ridge = Ridge(alpha=alpha, max_iter=9999999).fit(X_train, y_train)\n",
    "    preds_tr=ridge.predict(X_train)\n",
    "    preds_te=ridge.predict(X_test)\n",
    "    r2_train.append(r2_score(y_train, preds_tr))\n",
    "    r2_test.append(r2_score(y_test, preds_te))\n",
    "#    rmse_train.append(root_mean_squared_error(y_train, preds_tr))\n",
    "#    rmse_test.append(root_mean_squared_error(y_test, preds_te))\n",
    "#    rmse_train.append(mean_squared_error(y_train, preds_tr, squared=False))  # deprecated function call\n",
    "#    rmse_test.append(mean_squared_error(y_test, preds_te, squared=False))  # deprecated function call\n",
    "    \n",
    "plt.semilogx(alphas, r2_train, label=\"Train\")    \n",
    "plt.semilogx(alphas, r2_test, label=\"Test\") \n",
    "#plt.plot(alphas, rmse_train, label=\"rmse Train\")    \n",
    "#plt.plot(alphas, rmse_test, label=\"rmse Test\") \n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"R2\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it is possible to inspect the values of the different parameters as $\\alpha$ changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#compute coefficients for many alpha values\n",
    "coefs=[]\n",
    "\n",
    "#alternative: 300 different values of alpha in [2^5...2^(-10)]\n",
    "alphas=2**np.arange(5,-10,-.05) \n",
    "for alpha in alphas:\n",
    "    ridge= Ridge(alpha=alpha, max_iter=100000).fit(X_train, y_train)\n",
    "    coefs.append(ridge.coef_)\n",
    "coefs=np.array(coefs)\n",
    "\n",
    "#plot results\n",
    "N,M=X_train.shape #get number of rows(N) which correspond to alphas and columns(M) which correspond to the variables)\n",
    "plt.figure(figsize=(10,7))\n",
    "for i in range(M):\n",
    "    plt.plot(alphas, coefs[:,i], label=\"Var %d\" % (i+1)) #the coefficents of variable i for each alpha value\n",
    "    \n",
    "plt.xscale(\"log\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"coefficients\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use scikit-learn own RidgeCV to find the best $\\alpha$ value using cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#lets find the best alpha using cross-validation on the training data  \n",
    "from sklearn.linear_model import RidgeCV\n",
    "ridge_cv = RidgeCV(alphas = alphas, cv=5).fit(X_train, y_train)\n",
    "print(\"The best alpha is: \",ridge_cv.alpha_)\n",
    "\n",
    "#plot results\n",
    "N,M=X_train.shape #get number of rows(N) which correspond to alphas and columns(M) which correspond to the variables)\n",
    "plt.figure(figsize=(10,7))\n",
    "for i in range(M):\n",
    "    plt.plot(alphas, coefs[:,i], label=\"Var %d\" % (i+1)) #the coefficents of variable i for each alpha value\n",
    "plt.axvline(x = ridge_cv.alpha_, color = 'b', label = 'best Alpha')\n",
    "plt.xscale(\"log\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"coefficients\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's fit the linear regression using the best alpha and evaluate on the test set\n",
    "ridge = Ridge(alpha=ridge_cv.alpha_, max_iter=100000).fit(X_train, y_train)\n",
    "preds_best=ridge.predict(X_test)\n",
    "printRegStatistics(y_test, preds_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Exercise 2:\n",
    "### Compare the results obtained with alpha=10, alpha=0.0001 and the best alpha. What can you conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice: all these values have been computed before...\n",
    "#insert your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"**<your answer here>**\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 The Lasso\n",
    "\n",
    "The Lasso (Least Absolute Shrinkage and Selection Operator) is similar to Ridge regression but it uses L1 regularization, that is, it minimizes not only the MSEs, but including the modulus values of the parameters estimators, which will have a very important effect on the actual parameters:\n",
    "\n",
    "$cost(\\beta) = MSE(\\theta) + \\alpha\\sum^{n}_{i=1}{|\\beta_i|}$\n",
    "\n",
    "This will make that only really necessary variables will enter the model. Similar to Ridge regression the  $\\alpha$ parameter defines how much to penalize the actual parameters. This penalization will emphasize the importance of each variable in its contribution for explaining `y`. \n",
    "Higher values of $\\alpha$, will cause smaller $\\beta$. However different from Ridge regression, due to the nature of the modulus function, for high alpha values only a few variables will enter the model. This is a very important criterion for actually identifying the most important variables in a model.\n",
    "\n",
    "Selecting a value of  $\\alpha=2$, for instance, will only have two variables in the model (\\=0), suggesting they are the most important ones for explaining `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = Lasso(alpha=2, max_iter=9999999).fit(X_train, y_train)\n",
    "print(\"The bias is: \",  L.intercept_)\n",
    "print(\"The other parameters are: \")\n",
    "for i, beta in enumerate(L.coef_):\n",
    "    print(\"\\t B%2d -> %9.3f\"% (i+1, beta))\n",
    "preds=L.predict(X_test)\n",
    "printRegStatistics(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making  $\\alpha=0.5$ will impact the model, showing now 4 active variables and an apparent increase in the model statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = Lasso(alpha=.5, max_iter=9999999).fit(X_train, y_train)\n",
    "\n",
    "print(\"The bias is: \",  L.intercept_)\n",
    "print(\"The other parameters are: \")\n",
    "for i, beta in enumerate(L.coef_):\n",
    "    print(\"\\t B%02d -> %9.3f\"% (i+1, beta))\n",
    "preds=L.predict(X_test)\n",
    "printRegStatistics(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3:\n",
    "Repeat the procedure above described for Ridge regression, but now adapted for the Lasso.\n",
    "\n",
    "### 3.1 Use cross-validation to decide on the best alpha value \n",
    "(suggestion: look for the corresponding function in scikit-learn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets find the best alpha using cross-validation on the training data... \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 See how the best alpha value impacts the values of the coefficients. How many are not zero?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Plot R2 vs. alpha values and print the best alpha value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Plot the distribution of alpha values and coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Logistic regression\n",
    "\n",
    "Despite the name, Logistic regression only uses regression methods for fitting, but what is fitted is the probability of belonging to a given class, making this a classification method. This probability function is totaly non-linear.\n",
    "\n",
    "\n",
    "### 4.1. A very simple explanation of Logistic Regression\n",
    "\n",
    "We will explain Logistic Regression using articially created data in two different files. One with positive and the other with negative samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=np.genfromtxt('pos_smps.txt')\n",
    "poss=np.array([float(lin) for lin in lines]).reshape(-1, 1) #array of positive examples\n",
    "Np=poss.shape[0] #number of positive examples\n",
    "lines=np.genfromtxt('neg_smps.txt')\n",
    "negs=np.array([float(lin) for lin in lines]).reshape(-1, 1) #array of negative examples\n",
    "Nn=negs.shape[0]  #number of positive examples\n",
    "\n",
    "yp=np.ones(Np) #array of labels for positive examples\n",
    "yn=np.zeros(Nn) #array of labels for negative example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the examples. for positives: y=1, for negatives: y=0\n",
    "plt.scatter(poss, yp, label=\"positives\")\n",
    "plt.scatter(negs, yn, label=\"negatives\")\n",
    "plt.ylim([-0.2, 1.2])\n",
    "plt.legend()\n",
    "plt.xlabel(\"X values\")\n",
    "plt.ylabel(\"y (classification) values\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to fit a logistic regression that will assign a probability that each instance is positive. That probability cab be defined with a logistic function, with a characteristic sigmoid shape:\n",
    "\n",
    "$p=\\dfrac{1}{1+e^{-(\\beta_0+\\beta_1.x)}}$\n",
    "\n",
    "this probability logistic curve is the probability curve. For each value of x, according to this logistic function we can compute the probability of each instance being positive. For this case, as it can be seen the largest the X, the highest the probability of it being positive. \n",
    "\n",
    "For illustration purposes as an initial guess, we are just going to assume two estimates for $\\beta_0$ and $\\beta_1$: \n",
    "\n",
    "* $\\beta_0= -10.0$\n",
    "* $\\beta_1= 4.0$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's plot\n",
    "b0 =-10.0\n",
    "b1 = 4.0\n",
    "x=np.arange(0, 8, 0.01) #x values to plot the\n",
    "p= 1/(1+np.exp(-(b0+b1*x))) #probability logistic\n",
    "\n",
    "plt.plot(x, p, c=\"k\")\n",
    "plt.scatter(poss, yp)\n",
    "plt.scatter(negs, yn)\n",
    "plt.xlabel(\"X values\")\n",
    "plt.ylabel(\"y (classification) values\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can solve the above equation relative to the probability to find that this curve is in fact a linear representation of the log odds. This *log odds* is the logarithm of the ratio that some instance is positive to the probability of it being negative:\n",
    "\n",
    "$\\log(\\frac{p}{1-p})=\\beta_0+\\beta_1.x$\n",
    "\n",
    "Now the log odds does not support neither the value of `p=1` neither `p=0`, each case implying $+\\infty$  and $-\\infty$ respectively. However we can project each point in the new line\n",
    "\n",
    "This can be represented graphically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_lo = b0 + b1*poss  #log odds for positives\n",
    "pn_lo = b0 + b1*negs  #log odds for negatives\n",
    "\n",
    "plt.scatter(poss, pp_lo, s = 20)\n",
    "plt.scatter(negs, pn_lo, s = 20)\n",
    "\n",
    "plt.axline((0, b0), slope=b1, c=\"k\") #the linear regression\n",
    "\n",
    "plt.ylim([-8,8])\n",
    "plt.title(\"Log Odds plot\")\n",
    "plt.xlabel(\"log odds of X values\")\n",
    "plt.ylabel(\"log odds of y (classification) values\")\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could of course project our samples into the logistic curve. The points above the 0.5 line are the points that should be considered that have a higher likelyhood of being positive, and for those below, have a higher likelyhood of being negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp= 1/(1+np.exp(-(b0+b1*poss)))\n",
    "pn= 1/(1+np.exp(-(b0+b1*negs)))\n",
    "plt.plot(x, p, c=\"k\")\n",
    "plt.scatter(poss, pp, s = 20)\n",
    "plt.scatter(negs, pn, s = 20)\n",
    "plt.axhline(.5,  linestyle=\"--\", color=\"r\")\n",
    "plt.xlabel(\"X values\")\n",
    "plt.ylabel(\"y (classification) values\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions are then the sigmoid function values resulting from the log odds which was fitted as a straight line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's first put all elements in a common X, y structure for later using with scikit-learn\n",
    "X=np.vstack((poss, negs))\n",
    "y=np.hstack((yp, yn))\n",
    "\n",
    "# let's reserve a test set aside, name with l for logistic\n",
    "Xl_train, Xl_test, yl_train, yl_test = train_test_split(X, y, test_size=0.2, random_state=22)\n",
    "\n",
    "#now we can make predictions with test set\n",
    "preds=(1/(1+np.exp(-(b0+b1*Xl_test)))>0.5)\n",
    "preds=preds.flatten().astype('int32')\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How good is this model? We need to compute the typical statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, matthews_corrcoef, confusion_matrix, accuracy_score\n",
    "import pandas as pd\n",
    "def printClassResults(truth, preds):\n",
    "    print(\"The Accuracy is: %7.4f\" % accuracy_score(truth, preds))\n",
    "    print(\"The Precision is: %7.4f\" % precision_score(truth, preds))\n",
    "    print(\"The Recall is: %7.4f\" % recall_score(truth, preds))\n",
    "    print(\"The F1 score is: %7.4f\" % f1_score(truth, preds))\n",
    "    print(\"The Matthews correlation coefficient is: %7.4f\" % matthews_corrcoef(truth, preds))\n",
    "    print()\n",
    "    print(\"This is the Confusion Matrix\")\n",
    "    print(pd.DataFrame(confusion_matrix(truth, preds)))\n",
    "\n",
    "printClassResults(yl_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n",
    "What if we change the parameters?\n",
    "\n",
    "Use $\\beta_0$ = `-6.0`, and  $\\beta_1$ = `2.0`\n",
    "(to make new predictions is trivial, we just use the new parameters in the formula to get new predictions and print the results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Logistic Regression on sickit-learn\n",
    "\n",
    "\n",
    "Differently from Linear Regression, the process for finding the best possible solution is heuristic, using typically gradient descent approaches. We can use scikit learn for finding the best possible parameters for the above problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "mdl = LogisticRegression()\n",
    "mdl.fit(Xl_train, yl_train)\n",
    "\n",
    "b0=mdl.intercept_[0]\n",
    "b1=mdl.coef_[0][0]\n",
    "print(\"Intercept (b0): %7.4f\"% b0) \n",
    "print(\"Slope     (b1): %7.4f\"% b1) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can furthermore see the curve and how it compares to the original model with training set used to fit the new curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pp= 1/(1+np.exp(-(b0+b1*poss)))\n",
    "#pn= 1/(1+np.exp(-(b0+b1*negs)))\n",
    "\n",
    "#this is the scikit fitted curve\n",
    "p_sk= 1/(1+np.exp(-(b0+b1*x)))\n",
    "\n",
    "#below is the original curve\n",
    "p_or= 1/(1+np.exp(-(-10.0+4.0*x)))\n",
    "\n",
    "plt.plot(x, p_sk, c=\"k\", label=\"scikit\")\n",
    "plt.plot(x, p_or, c=\"b\", label=\"original\")\n",
    "plt.scatter(Xl_train, yl_train, s = 20)\n",
    "#plt.scatter(poss, yp, s = 20)\n",
    "#plt.scatter(negs, yn, s = 20)\n",
    "plt.axhline(.5,  linestyle=\"--\", color=\"r\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can compare the metrics computing them for the new model, using the test set now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_preds=mdl.predict(Xl_test)\n",
    "printClassResults(yl_test, sk_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "Compare the results obtained and discuss them\n",
    "    * What to you think is happening in scikit-learn\n",
    "    * how relevant is the aspect of the curve to the overal statistics. Focus in particular on precision and recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Scikit-learn example on multidimensional data\n",
    "\n",
    "Scikit is able to fit logistic regression parameters to multidimensional data and with multiclass objectives. However some care must be taken when there is more than one independent variable. Due to the learning process, it is fundamental that the data is apropriately scaled\n",
    "\n",
    "Furthermore, now we will use tradidional cross validation to evaluate our models\n",
    "\n",
    "#### 4.2.1 Scaling data\n",
    "\n",
    "Due to the process of model fitting it is required that the X matrix has been scaled to 0 mean and variance of 1. Scikit learn has a tool that is able to accomplish this (`StandardScaler`) but we must be careful to maintain a separation between training and testing or the Scaling process will be a source of error.\n",
    "\n",
    "The correct procedure for scaling data is as follows\n",
    "1. Separate full data set into training and testing\n",
    "2. Use the training set to fit the scaler\n",
    "3. Apply the scaler to the training set (transform)\n",
    "4. Apply the scaler to the testing set (transform)\n",
    "\n",
    "We are going to use the Breast Cancer data set from the scikit learn toy data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "X_bc,y_bc = load_breast_cancer(return_X_y=True)\n",
    "Xl_train, Xl_test, yl_train, yl_test = train_test_split(X_bc, y_bc, test_size=0.2, random_state=22)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(Xl_train) #fit scaler on training set\n",
    "Xl_train = scaler.transform(Xl_train)  #apply scaler on training set\n",
    "Xl_test = scaler.transform(Xl_test) #apply scaler on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2. Fitting the model\n",
    "\n",
    "Now let's fit the model to the training data properly scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl= LogisticRegression(random_state=0).fit(Xl_train, yl_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print the coefficients of the model. Please note that we would require several sets of parameters if the problem is multiclass. For 3 classes we would require 3 parameter sets. This will force us to use a slightly different way to have access to each of the actual model coefficients\n",
    "\n",
    "Also note that as all variables are centered in zero and with similar variance it is possible to identify the variables that may have strongest impact on the model as these are the ones with higher absolute value on the coeficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The bias is: \",  mdl.intercept_[0])\n",
    "print(\"The other parameters are: \")\n",
    "for i, beta in enumerate(mdl.coef_[0]):\n",
    "    print(\"\\t B%02d -> %9.3f\"% (i+1, beta))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may look at the five most influent (those with higher absolute value):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs=[(beta,i) for i, beta in enumerate(mdl.coef_[0])]\n",
    "coefss=sorted(coefs, key=lambda row: np.abs(row[0]))\n",
    "coefss.reverse()\n",
    "for beta, i in coefss[:5]:\n",
    "    print(\"\\t B%02d -> %9.3f\"% (i+1, beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can make predictions and evaluation with the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = mdl.predict(Xl_test)\n",
    "\n",
    "printClassResults(yl_test, preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
